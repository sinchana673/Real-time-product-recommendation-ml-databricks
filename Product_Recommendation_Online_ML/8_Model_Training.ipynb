{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4373f5a3-f3d9-4771-8a3b-88c7573cafc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Notebook Summary: Product Recommendation Pipeline\n",
    "\n",
    "## 1. Data Preparation\n",
    "- Loaded training and validation snapshots from Delta tables.\n",
    "- Selected features and label for model training.\n",
    "- Handled class imbalance using `scale_pos_weight`.\n",
    "\n",
    "## 2. Model Training & Evaluation\n",
    "- Trained an XGBoost classifier with regularization to prevent overfitting and leakage.\n",
    "- Evaluated model using AUC and ranking metrics (Recall@K, Precision@K, HitRate@K).\n",
    "- Logged metrics, parameters, and feature list to MLflow.\n",
    "- Registered the trained model in MLflow Model Registry.\n",
    "\n",
    "## 3. Inference & Recommendation Generation\n",
    "- Loaded the registered model for inference.\n",
    "- Pulled candidate features and product details from feature store and product tables.\n",
    "- Generated prediction scores for candidates.\n",
    "- Computed a rule-based score using business signals.\n",
    "- Combined model and rule scores for a hybrid ranking.\n",
    "\n",
    "## 4. Explainability & Output\n",
    "- Created human-readable recommendation reasons for each product.\n",
    "- Selected Top-K recommendations per user.\n",
    "- Structured recommendations in a JSON-ready format.\n",
    "- Stored final recommendations in a Delta table.\n",
    "\n",
    "## 5. Utility & API\n",
    "- Provided a function to fetch recommendations for a given user in API-style JSON.\n",
    "- Previewed and validated the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59d2bea4-315b-4482-9ee9-2d48f54ed978",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FINAL MODEL TRAINING + EVALUATION + REGISTRATION\n",
    "# (REALISTIC, REGULARIZED, LEAKAGE-FREE)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "spark.conf.set(\"spark.databricks.remoteFiltering.blockSelfJoins\", \"false\")\n",
    "\n",
    "gold = \"kusha_solutions.product_recomendation\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1Ô∏è‚É£ LOAD SNAPSHOTS (TIME-SAFE)\n",
    "# ------------------------------------------------------------\n",
    "train_df = spark.table(f\"{gold}.ml_train_snapshot\").toPandas()\n",
    "valid_df = spark.table(f\"{gold}.ml_valid_snapshot\").toPandas()\n",
    "\n",
    "print(\"Train rows:\", train_df.shape)\n",
    "print(\"Valid rows:\", valid_df.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ FEATURES & LABEL\n",
    "# ------------------------------------------------------------\n",
    "TARGET_COL = \"label\"\n",
    "\n",
    "DROP_COLS = [\n",
    "    \"CustomerID\",\n",
    "    \"ProductID\",\n",
    "    TARGET_COL,\n",
    "    \"snapshot_id\",\n",
    "    \"snapshot_ts\",\n",
    "    \"feature_cutoff\",\n",
    "    \"valid_cutoff\"\n",
    "]\n",
    "\n",
    "FEATURE_COLS = [c for c in train_df.columns if c not in DROP_COLS]\n",
    "\n",
    "X_train = train_df[FEATURE_COLS]\n",
    "y_train = train_df[TARGET_COL]\n",
    "\n",
    "X_valid = valid_df[FEATURE_COLS]\n",
    "y_valid = valid_df[TARGET_COL]\n",
    "\n",
    "print(\"Number of features:\", len(FEATURE_COLS))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ CLASS IMBALANCE (CAPPED ‚Äî IMPORTANT)\n",
    "# ------------------------------------------------------------\n",
    "pos = y_train.sum()\n",
    "neg = len(y_train) - pos\n",
    "\n",
    "raw_spw = neg / pos\n",
    "scale_pos_weight = min(raw_spw, 300)   # üëà critical change\n",
    "\n",
    "print(\"raw scale_pos_weight:\", raw_spw)\n",
    "print(\"used scale_pos_weight:\", scale_pos_weight)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ START MLFLOW EXPERIMENT\n",
    "# ------------------------------------------------------------\n",
    "mlflow.set_experiment(\"/Shared/product_recommendation_xgb\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"xgb_recommender_v4_regularized\"):\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 5Ô∏è‚É£ MODEL (INTENTIONALLY REGULARIZED)\n",
    "    # --------------------------------------------------------\n",
    "    model = XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        n_estimators=120,\n",
    "        max_depth=3,             # weaker trees\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.6,\n",
    "        min_child_weight=20,     # prevents tiny splits\n",
    "        gamma=2.0,               # penalize splits\n",
    "        reg_alpha=1.5,           # stronger L1\n",
    "        reg_lambda=3.0,          # stronger L2\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 6Ô∏è‚É£ TRAIN\n",
    "    # --------------------------------------------------------\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 7Ô∏è‚É£ MODEL SCORES (VALIDATION)\n",
    "    # --------------------------------------------------------\n",
    "    valid_df[\"prediction_score\"] = model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(y_valid, valid_df[\"prediction_score\"])\n",
    "    print(\"‚úÖ Validation AUC:\", auc)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 8Ô∏è‚É£ RANKING METRICS (MODEL ONLY)\n",
    "    # --------------------------------------------------------\n",
    "    K = 10\n",
    "    recalls, precisions, hitrates = [], [], []\n",
    "\n",
    "    for _, user_df in valid_df.groupby(\"CustomerID\"):\n",
    "\n",
    "        actual = set(user_df[user_df[TARGET_COL] == 1][\"ProductID\"])\n",
    "        if not actual:\n",
    "            continue\n",
    "\n",
    "        top_k = (\n",
    "            user_df\n",
    "            .sort_values(\"prediction_score\", ascending=False)\n",
    "            .head(K)[\"ProductID\"]\n",
    "            .tolist()\n",
    "        )\n",
    "\n",
    "        hits = len(set(top_k) & actual)\n",
    "\n",
    "        recalls.append(hits / len(actual))\n",
    "        precisions.append(hits / K)\n",
    "        hitrates.append(1 if hits > 0 else 0)\n",
    "\n",
    "    recall_k = float(np.mean(recalls))\n",
    "    precision_k = float(np.mean(precisions))\n",
    "    hitrate_k = float(np.mean(hitrates))\n",
    "\n",
    "    print(f\"üìä Recall@{K}:    {recall_k:.4f}\")\n",
    "    print(f\"üìä Precision@{K}: {precision_k:.4f}\")\n",
    "    print(f\"üìä HitRate@{K}:   {hitrate_k:.4f}\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 9Ô∏è‚É£ LOG METRICS\n",
    "    # --------------------------------------------------------\n",
    "    mlflow.log_metric(\"val_auc\", auc)\n",
    "    mlflow.log_metric(f\"recall@{K}\", recall_k)\n",
    "    mlflow.log_metric(f\"precision@{K}\", precision_k)\n",
    "    mlflow.log_metric(f\"hitrate@{K}\", hitrate_k)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # üîü LOG PARAMETERS\n",
    "    # --------------------------------------------------------\n",
    "    mlflow.log_param(\"n_estimators\", 120)\n",
    "    mlflow.log_param(\"max_depth\", 3)\n",
    "    mlflow.log_param(\"learning_rate\", 0.05)\n",
    "    mlflow.log_param(\"subsample\", 0.7)\n",
    "    mlflow.log_param(\"colsample_bytree\", 0.6)\n",
    "    mlflow.log_param(\"min_child_weight\", 20)\n",
    "    mlflow.log_param(\"gamma\", 2.0)\n",
    "    mlflow.log_param(\"reg_alpha\", 1.5)\n",
    "    mlflow.log_param(\"reg_lambda\", 3.0)\n",
    "    mlflow.log_param(\"scale_pos_weight\", scale_pos_weight)\n",
    "    mlflow.log_param(\"num_features\", len(FEATURE_COLS))\n",
    "    mlflow.log_param(\"top_k\", K)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 1Ô∏è‚É£1Ô∏è‚É£ LOG FEATURE LIST\n",
    "    # --------------------------------------------------------\n",
    "    mlflow.log_text(\n",
    "        \"\\n\".join(FEATURE_COLS),\n",
    "        artifact_file=\"features_used.txt\"\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 1Ô∏è‚É£2Ô∏è‚É£ LOG & REGISTER MODEL\n",
    "    # --------------------------------------------------------\n",
    "    signature = infer_signature(\n",
    "        X_valid.head(20),\n",
    "        model.predict_proba(X_valid.head(20))\n",
    "    )\n",
    "\n",
    "    mlflow.xgboost.log_model(\n",
    "        model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"Product_Recommendation_Ranker\",\n",
    "        signature=signature,\n",
    "        input_example=X_valid.head(5)\n",
    "    )\n",
    "\n",
    "print(\"üéâ Model training, evaluation & registration completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39b47a39-c26b-4460-8f5a-59a0938f5d72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FINAL MODEL INFERENCE + HYBRID RANKING + REASONS\n",
    "# ============================================================\n",
    "\n",
    "import mlflow.pyfunc\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# CONFIG\n",
    "# ------------------------------------------------------------\n",
    "MODEL_URI = \"models:/kusha_solutions.default.product_recommendation_ranker@prod\"\n",
    "TOP_K = 10\n",
    "\n",
    "FEATURE_STORE_TABLE = (\n",
    "    \"kusha_solutions.product_recomendation.fs_canddiate_features\"\n",
    ")\n",
    "\n",
    "PRODUCT_TABLE = (\n",
    "    \"kusha_solutions.product_recomendation.gold_product_features\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1Ô∏è‚É£ LOAD MODEL (UNITY CATALOG ALIAS)\n",
    "# ------------------------------------------------------------\n",
    "model = mlflow.pyfunc.load_model(MODEL_URI)\n",
    "print(\"‚úÖ Model loaded using UC alias (@prod)\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ LOAD FEATURE STORE DATA (MODEL INPUT)\n",
    "# ------------------------------------------------------------\n",
    "features = spark.table(FEATURE_STORE_TABLE).toPandas()\n",
    "\n",
    "products = (\n",
    "    spark.table(PRODUCT_TABLE)\n",
    "         .select(\"ProductID\", \"ProductName\", \"Brand\")\n",
    "         .toPandas()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Feature store rows:\", features.shape[0])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ EXACT FEATURE LIST (MUST MATCH TRAINING)\n",
    "# ------------------------------------------------------------\n",
    "FEATURE_COLS = [\n",
    "    \"src_same_category\",\n",
    "    \"src_brand_affinity\",\n",
    "    \"src_fbt\",\n",
    "    \"src_trending\",\n",
    "    \"src_age_group\",\n",
    "    \"src_location\",\n",
    "    \"user_views\",\n",
    "    \"user_carts\",\n",
    "    \"user_purchases\",\n",
    "    \"recent_7d_interaction\",\n",
    "    \"ProductRating\",\n",
    "    \"ReviewsCount\",\n",
    "    \"DiscountPercent\",\n",
    "    \"log_reviews\",\n",
    "    \"is_discounted\",\n",
    "    \"AvgReviewRating\",\n",
    "    \"age_group_encoded\",\n",
    "    \"num_sources\"\n",
    "]\n",
    "\n",
    "X = features[FEATURE_COLS]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ MODEL PREDICTION\n",
    "# ------------------------------------------------------------\n",
    "features[\"prediction_score\"] = model.predict(X)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5Ô∏è‚É£ RULE-BASED SCORE (BUSINESS SIGNALS)\n",
    "# ------------------------------------------------------------\n",
    "features[\"rule_score\"] = (\n",
    "    0.30 * features[\"src_trending\"] +\n",
    "    0.25 * features[\"is_discounted\"] +\n",
    "    0.20 * features[\"src_brand_affinity\"] +\n",
    "    0.10 * features[\"src_fbt\"] +\n",
    "    0.10 * features[\"src_same_category\"] +\n",
    "    0.05 * features[\"src_location\"] +\n",
    "    0.05 * features[\"src_age_group\"] +\n",
    "    0.05 * features[\"num_sources\"]\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6Ô∏è‚É£ FINAL HYBRID SCORE\n",
    "# ------------------------------------------------------------\n",
    "features[\"final_score\"] = (\n",
    "    0.7 * features[\"prediction_score\"] +\n",
    "    0.3 * features[\"rule_score\"]\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7Ô∏è‚É£ ADD PRODUCT DETAILS\n",
    "# ------------------------------------------------------------\n",
    "features = features.merge(products, on=\"ProductID\", how=\"left\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8Ô∏è‚É£ RECOMMENDATION REASON (EXPLAINABILITY)\n",
    "# ------------------------------------------------------------\n",
    "def build_reason(row):\n",
    "    reasons = []\n",
    "\n",
    "    if row[\"src_brand_affinity\"] == 1:\n",
    "        reasons.append(\"Based on your brand preference\")\n",
    "\n",
    "    if row[\"src_same_category\"] == 1:\n",
    "        reasons.append(\"From categories you like\")\n",
    "\n",
    "    if row[\"src_fbt\"] == 1:\n",
    "        reasons.append(\"Frequently bought together with your past purchases\")\n",
    "\n",
    "    if row[\"src_trending\"] == 1:\n",
    "        reasons.append(\"Trending among users\")\n",
    "\n",
    "    if row[\"is_discounted\"] == 1:\n",
    "        reasons.append(\"Currently on discount\")\n",
    "\n",
    "    if row[\"src_location\"] == 1:\n",
    "        reasons.append(\"Popular in your location\")\n",
    "\n",
    "    if row[\"src_age_group\"] == 1:\n",
    "        reasons.append(\"Popular among similar age group\")\n",
    "\n",
    "    if row[\"recent_7d_interaction\"] == 1 and not reasons:\n",
    "        reasons.append(\"Based on your recent activity\")\n",
    "\n",
    "    return \", \".join(reasons) if reasons else \"General popularity\"\n",
    "\n",
    "features[\"recommendation_reason\"] = features.apply(build_reason, axis=1)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9Ô∏è‚É£ TOP-K RECOMMENDATIONS PER USER\n",
    "# ------------------------------------------------------------\n",
    "top_k = (\n",
    "    features\n",
    "    .sort_values([\"CustomerID\", \"final_score\"], ascending=[True, False])\n",
    "    .groupby(\"CustomerID\")\n",
    "    .head(TOP_K)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# üîü FINAL OUTPUT (JSON-READY STRUCTURE)\n",
    "# ------------------------------------------------------------\n",
    "final_recommendations = (\n",
    "    top_k\n",
    "    .groupby(\"CustomerID\")\n",
    "    .apply(lambda x: [\n",
    "        {\n",
    "            \"product_id\": int(r.ProductID),\n",
    "            \"product_name\": r.ProductName,\n",
    "            \"brand\": r.Brand,\n",
    "            \"score\": round(r.final_score, 5),\n",
    "            \"reason\": r.recommendation_reason\n",
    "        }\n",
    "        for r in x.itertuples()\n",
    "    ])\n",
    "    .reset_index(name=\"recommendations\")\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ PREVIEW\n",
    "# ------------------------------------------------------------\n",
    "final_recommendations.head(10)\n",
    "\n",
    "\n",
    "\n",
    "final_recommendations[\"generated_at\"] = datetime.now()\n",
    "\n",
    "spark.createDataFrame(final_recommendations) \\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\n",
    "        \"kusha_solutions.product_recomendation.user_recommendations\"\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Recommendations successfully stored in table\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18ea590e-f388-47bc-acb0-a437246b1c1f",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1767771538293}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM kusha_solutions.product_recomendation.user_recommendations\n",
    ";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c08830d7-b357-4f47-9245-cb065a370e5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "row_count = spark.read.table(\"kusha_solutions.product_recomendation.user_recommendations\").count()\n",
    "print(\"Row count:\", row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d87db3c-f5ed-4253-b6b6-38068ecfebf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_recommendations_for_user(\n",
    "    customer_id: int,\n",
    "    final_recommendations_df,\n",
    "    top_k: int = 10\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns API-style recommendation JSON for a given customer_id\n",
    "    \"\"\"\n",
    "\n",
    "    user_rows = final_recommendations_df[\n",
    "        final_recommendations_df[\"CustomerID\"] == customer_id\n",
    "    ]\n",
    "\n",
    "    if user_rows.empty:\n",
    "        return {\n",
    "            \"customer_id\": customer_id,\n",
    "            \"recommendations\": [],\n",
    "            \"message\": \"No recommendations available for this user\"\n",
    "        }\n",
    "\n",
    "    recs = user_rows.iloc[0][\"recommendations\"][:top_k]\n",
    "\n",
    "    return {\n",
    "        \"customer_id\": int(customer_id),\n",
    "        \"recommendations\": recs\n",
    "    }\n",
    "\n",
    "customer_id = 3   # üëà dynamic input\n",
    "response = get_recommendations_for_user(customer_id, final_recommendations)\n",
    "\n",
    "print(json.dumps(response, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3390fb78-3a18-4301-9e9d-bdf35c9ca0aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS kusha_solutions.product_recomendation.user_recommendations (\n",
    "  customer_id        BIGINT,\n",
    "  recommendations    STRING,      -- JSON string\n",
    "  generated_at       TIMESTAMP\n",
    ")\n",
    "USING DELTA;\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6095390805299730,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "8_Model_Training",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
